{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing and Data Augmentation\n",
    "\n",
    "In this file we read data from all participants. Using Open CV we detect blob of touch area and crop them out from original capacitive touch matrix and append in a new column in the same dataframe. \n",
    "Later after cropping we run filtering on the cropped images to remove noise and empty images (blob area less than 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_detection(cap_matrix):\n",
    "    cap_matrix[cap_matrix < 0] = 0 #Negative pixel values are set to 0.\n",
    "    \n",
    "    image = np.array(abs(cap_matrix),dtype=np.uint8,copy = True)\n",
    "    \n",
    "    #Pixels below this threshold considered as noise.\n",
    "    threshold=30\n",
    "    ret, threshold = cv2.threshold (image,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours will return contours from Threshold image.\n",
    "    _ ,contours, _ = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #If there is no contours return null coordinates.\n",
    "    if (contours ==[]):\n",
    "        rec_pts = [(0,0),(0,0)]\n",
    "\n",
    "    else:\n",
    "        c = max(contours, key = cv2.contourArea) #Determines maximum area contour.\n",
    "\n",
    "        # determine the most extreme points along the contour\n",
    "        extLeft  = tuple(c[c[:,:, 0].argmin()][0])\n",
    "        extRight = tuple(c[c[:,:, 0].argmax()][0])\n",
    "        extTop   = tuple(c[c[:,:, 1].argmin()][0])\n",
    "        extBot   = tuple(c[c[:,:, 1].argmax()][0])\n",
    "\n",
    "        alist = [extLeft,extRight,extTop,extBot]\n",
    "        temp  = tuple(map(sorted, zip(*alist)))\n",
    "        min_x, max_x, min_y, max_y = temp[0][0], temp[0][-1], temp[1][0], temp[1][-1]\n",
    "        #print(min_x, max_x, min_y, max_y)\n",
    "\n",
    "        extreme_left  = (min_x,min_y)\n",
    "        extreme_right = (max_x,max_y)\n",
    "    \n",
    "\n",
    "        rec_pts = [extreme_left,extreme_right]\n",
    "            \n",
    "    return rec_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(n):\n",
    "    \n",
    "    df_ud = df_new.copy(deep=True)\n",
    "    \n",
    "    for i in range(df_ud.shape[0]):\n",
    "        df_ud.at[i,'Cropped_Matrix'] = np.flipud(df_new.Cropped_Matrix[i])\n",
    "\n",
    "    df_original_axes = pd.concat([df_new,df_ud],ignore_index=True)\n",
    "\n",
    "    df_lr = df_original_axes.copy(deep=True)\n",
    "\n",
    "    for i in range(df_original_axes.shape[0]):\n",
    "        df_lr.at[i,'Cropped_Matrix'] = np.fliplr(df_original_axes.Cropped_Matrix[i])\n",
    "        \n",
    "    df_final = pd.concat([df_original_axes,df_lr],ignore_index=True)\n",
    "    print('Writing data for Participant '+str(n))\n",
    "    \n",
    "    #Save augmented data file for individual participant.\n",
    "    df_final.to_pickle('DataSet_Phalanx/03_Augmented_DataSet/data'+str(n)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Participant 1.\n",
      "Number of noisy images deleted are -  9559 .\n",
      "Writing data for Participant 3\n",
      "Reading data from Participant 4.\n",
      "Number of noisy images deleted are -  12650 .\n",
      "Writing data for Participant 4\n",
      "Reading data from Participant 5.\n",
      "Number of noisy images deleted are -  14757 .\n",
      "Writing data for Participant 5\n",
      "Reading data from Participant 6.\n",
      "Number of noisy images deleted are -  15881 .\n",
      "Writing data for Participant 6\n",
      "Reading data from Participant 7.\n",
      "Number of noisy images deleted are -  18617 .\n",
      "Writing data for Participant 7\n",
      "Reading data from Participant 8.\n",
      "Number of noisy images deleted are -  11551 .\n",
      "Writing data for Participant 8\n",
      "Reading data from Participant 9.\n",
      "Number of noisy images deleted are -  12818 .\n",
      "Writing data for Participant 9\n",
      "Reading data from Participant 10.\n",
      "Number of noisy images deleted are -  13694 .\n",
      "Writing data for Participant 10\n",
      "Reading data from Participant 11.\n",
      "Number of noisy images deleted are -  11618 .\n",
      "Writing data for Participant 11\n",
      "Reading data from Participant 12.\n",
      "Number of noisy images deleted are -  9902 .\n",
      "Writing data for Participant 12\n",
      "Reading data from Participant 13.\n",
      "Number of noisy images deleted are -  12117 .\n",
      "Writing data for Participant 13\n",
      "Reading data from Participant 14.\n",
      "Number of noisy images deleted are -  12792 .\n",
      "Writing data for Participant 14\n",
      "Reading data from Participant 15.\n",
      "Number of noisy images deleted are -  13395 .\n",
      "Writing data for Participant 15\n",
      "Reading data from Participant 16.\n",
      "Number of noisy images deleted are -  16612 .\n",
      "Writing data for Participant 16\n",
      "Reading data from Participant 17.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Read data files of all participants for Pre-processing.\n",
    "rec_pts = np.zeros(2)\n",
    "\n",
    "for i in range(1,26):\n",
    "    \n",
    "    DATA_PATH ='DataSet_Phalanx/01_Input_Data/data'+str(i)+'.pkl'\n",
    "    print('Reading data from Participant '+str(i)+'.')\n",
    "    data_frame = pd.read_pickle(DATA_PATH)\n",
    "    cropped = []\n",
    "    \n",
    "    for j,matrix in enumerate(data_frame.Matrix):\n",
    "       \n",
    "        cap_matrix = reshape(matrix,(27,15))\n",
    "        rec_pts = blob_detection(cap_matrix) #Run blob detection on reshaped capacitive matrix.  \n",
    "        \n",
    "        #Cropping capacitive matrix with blob coordinates with offset of 1 extra row and column.\n",
    "        crop_matrix = cap_matrix[rec_pts[0][1]-1:rec_pts[1][1]+1,rec_pts[0][0]-1:rec_pts[1][0]+1]\n",
    "        cropped.append(crop_matrix)\n",
    "        \n",
    "    data_frame['Cropped_Matrix'] = pd.Series(cropped)\n",
    "    \n",
    "    df_new = data_frame.copy(deep=False)\n",
    "            \n",
    "    counter =0\n",
    "    \n",
    "    for k,cm in enumerate(df_new.Cropped_Matrix):\n",
    "        area_min = cm.shape[0]*cm.shape[1]\n",
    "        if(area_min>5):\n",
    "            pass # If area is greater than 5 pixel proceed as normal. \n",
    "        else:\n",
    "            counter = counter +1 #will keep track of deleted images.\n",
    "            df_new.drop(k, inplace=True) # Drop the corresponding row from data frame.\n",
    "            \n",
    "    df_new = df_new.reset_index()\n",
    "    print(\"Number of noisy images deleted are - \",counter,'.')\n",
    "    \n",
    "    # Store individual participant's pre processed data as pickle before augmentation. \n",
    "    df_new.to_pickle('DataSet_Phalanx/02_Pre_Processed_Data/data_new'+str(i)+'.pkl')\n",
    "    \n",
    "    # Before running augmentation on data set, drop the following columns which are not necessary for training set.\n",
    "    List = ['Handedness','Finger','index','Timestamp','Matrix']\n",
    "    df_new=df_new.drop(List, axis=1)\n",
    "    data_augmentation(i) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
